{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77d10c15",
   "metadata": {},
   "source": [
    "### DEEP LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff65877",
   "metadata": {},
   "source": [
    "## **TEXT SUMMARIZATION MODEL**\n",
    "## **BART FINE TUNING MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe043465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, get_linear_schedule_with_warmup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import rouge_score\n",
    "from rouge_score import rouge_scorer\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK data\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "# Set random seeds and device\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbcf0d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataframe shape: (287114, 3)\n",
      "Test dataframe shape: (11491, 3)\n",
      "Validation dataframe shape: (13369, 3)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/train.csv', header=None)\n",
    "test_df = pd.read_csv('../data/test.csv', header=None)\n",
    "val_df = pd.read_csv('../data/validation.csv', header=None)\n",
    "\n",
    "columns = ['id', 'article', 'summary']\n",
    "train_df.columns = columns\n",
    "test_df.columns = columns\n",
    "val_df.columns = columns\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "def clean_article_heading(article):\n",
    "    pattern = r'By\\s*\\.\\s*.*?\\s*\\.\\s*PUBLISHED:\\s*\\.\\s*\\d+:\\d+\\s*EST,\\s*\\d+\\s*[A-Za-z]+\\s*\\d+\\s*\\.\\s*\\|\\s*\\.\\s*UPDATED:\\s*\\.\\s*\\d+:\\d+\\s*EST,\\s*\\d+\\s*[A-Za-z]+\\s*\\d+\\s*\\.'\n",
    "    cleaned_text = re.sub(pattern, '', article)\n",
    "    return cleaned_text.strip()\n",
    "\n",
    "train_df['article'] = train_df['article'].apply(preprocess_text)\n",
    "train_df['article'] = train_df['article'].apply(clean_article_heading)\n",
    "train_df['summary'] = train_df['summary'].apply(preprocess_text)\n",
    "test_df['article'] = test_df['article'].apply(preprocess_text)\n",
    "test_df['article'] = test_df['article'].apply(clean_article_heading)\n",
    "test_df['summary'] = test_df['summary'].apply(preprocess_text)\n",
    "val_df['article'] = val_df['article'].apply(preprocess_text)\n",
    "val_df['article'] = val_df['article'].apply(clean_article_heading)\n",
    "val_df['summary'] = val_df['summary'].apply(preprocess_text)\n",
    "\n",
    "print(f\"Training dataframe shape: {train_df.shape}\")\n",
    "print(f\"Test dataframe shape: {test_df.shape}\")\n",
    "print(f\"Validation dataframe shape: {val_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dbfd400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" train_df['article'] = train_df['article'].apply(lambda x: preprocessor.preprocess(x, remove_stopwords=False))\\ntrain_df['summary'] = train_df['summary'].apply(lambda x: preprocessor.preprocess(x, remove_stopwords=False))\\n\\nval_df['article'] = val_df['article'].apply(lambda x: preprocessor.preprocess(x, remove_stopwords=False))\\nval_df['summary'] = val_df['summary'].apply(lambda x: preprocessor.preprocess(x, remove_stopwords=False))\\n\\ntest_df['article'] = test_df['article'].apply(lambda x: preprocessor.preprocess(x, remove_stopwords=False))\\ntest_df['summary'] = test_df['summary'].apply(lambda x: preprocessor.preprocess(x, remove_stopwords=False)) \""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TextPreprocessor:\n",
    "    \"\"\"Text preprocessing utilities for news articles.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        \"\"\"Clean and normalize text.\"\"\"\n",
    "        # Remove special characters and digits\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        # Remove extra whitespace\n",
    "        text = ' '.join(text.split())\n",
    "        return text\n",
    "    \n",
    "    def remove_stopwords(self, text):\n",
    "        \"\"\"Remove stopwords from text.\"\"\"\n",
    "        words = word_tokenize(text)\n",
    "        filtered_words = [word for word in words if word not in self.stop_words]\n",
    "        return ' '.join(filtered_words)\n",
    "    \n",
    "    def preprocess(self, text, remove_stopwords=False):\n",
    "        \"\"\"Apply all preprocessing steps.\"\"\"\n",
    "        text = self.clean_text(text)\n",
    "        if remove_stopwords:\n",
    "            text = self.remove_stopwords(text)\n",
    "        return text\n",
    "    \n",
    "    # Initialize preprocessor\n",
    "preprocessor = TextPreprocessor()\n",
    "\n",
    "\"\"\" train_df['article'] = train_df['article'].apply(lambda x: preprocessor.preprocess(x, remove_stopwords=False))\n",
    "train_df['summary'] = train_df['summary'].apply(lambda x: preprocessor.preprocess(x, remove_stopwords=False))\n",
    "\n",
    "val_df['article'] = val_df['article'].apply(lambda x: preprocessor.preprocess(x, remove_stopwords=False))\n",
    "val_df['summary'] = val_df['summary'].apply(lambda x: preprocessor.preprocess(x, remove_stopwords=False))\n",
    "\n",
    "test_df['article'] = test_df['article'].apply(lambda x: preprocessor.preprocess(x, remove_stopwords=False))\n",
    "test_df['summary'] = test_df['summary'].apply(lambda x: preprocessor.preprocess(x, remove_stopwords=False)) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f59ff998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "023b9cf4dfeca75635957a73408fde39705c9d4f\n",
      "by james rush a fatheroftwo left his wedding ring and watch to give to his children in case something happened to him before boarding the missing malaysia airlines flight as he flew out to start a dream job in mongolia mechanical engineer paul weeks of perth australia was on the flight as he made his way to his first shift in a flyin flyout job his wife danica has revealed how he left the objects with her to give to their two boys if something was to happen to him fatheroftwo paul weeks was on board the missing flight mh as he flew out to mongolia to start a dream job mrs weeks however said on sunday that she was praying for a miracle as she waited for news of him she told news national in perth he said if something should happen to me then the wedding ring should go to the first son that gets married and then the watch to the second the former soldier who was born in new zealand moved his young family to perth after their home in christchurch was devastated by earthquakes the couple have a threeyearold son called lincoln and an monthold called jack mr weeks was believed to have got a new job with transwest mongolia mrs weeks said before he left he took lots of photos of his family she told wa today i cant give up hope i would love him to walk through that door hold him one more time i see him everywhere in the house mr weekss wife danica has said her husband left his wedding ring and watch in case something happened to him mrs weeks has said she cant give up hope after the malaysia airlines flight went missing early saturday morning mr weeks was one of passengers and crew members on board the malaysia airlines flight which went missing early saturday morning as it made its way from kuala lumpur to beijing the manifest included passengers from china from malaysia seven from indonesia six from australia five from india three from the us and others from indonesia france new zealand canada ukraine russia taiwan and the netherlands a midair explosion the lack of debris could be explained by it falling into malaysian jungle a terrorist attack director of cia has said terrorism could not be ruled out power failure possibly caused by deliberate cutting of power to communication instruments electronic warfare passengers on board were experts in this technology hijacking radar data indicates the plane might have made a uturn a pilot error there is a chance of them in all air mysteries claim experts structural failure possibly involving damage sustained by an accident in pilot suicide there were two large jet crashes in the late s caused by this aeronautical black hole plane is stranded hundreds of miles from current search area among those travelling on the flight was a group of eight chinese and malaysian employees of austin texas semiconductor company freescale which said it was assembling aroundtheclock support for their families for seasoned australian travellers robert lawton and his wife catherine the seemingly routine takeoff of flight mh was the beginning of another adventure sharing their adventure was another something australian couple rodney and mary burrows neighbor don stokes said the trip was intended as the beginning of the next step in their life among the family groups on board were teenage sweethearts hadrien wattrelos and zhao yan students at a french school in beijing who were returning from the malaysian leg of a twoweek holiday along with hadriens mother and younger sister in december zhao changed her facebook profile photo to one of her and hadrien he had commented je taime followed by a heart and she had liked his comment some boarded the plane with more serious purposes in mind colleagues of chandrika sharma said the yearold director of the chennai chapter of an organization that works with fishermen was on her way from the southern indian city to mongolia for a food and agriculture organization conference more than three days after the boeing disappeared no trace of the plane has been found in waters between malaysia and vietnam that have been scoured by more than planes and ships from at least nations catherine and robert lawton from brisbane were named as one of three couples from australia who were missing french teenagers zhao yan and hadrien wattrelos had enrolled together at the lycee francais international de pekin both are believed to have been on board the plane dropped off radar less than an hour into the flight without sending out a distress signal authorities have said it may have attempted to turn back to kuala lumpur but they expressed surprise that it would do so without informing ground control malaysia airlines has said in a statement that search and rescue teams expanded their scope to the malacca strait between malaysias western coast and indonesias sumatra island the opposite side of malaysia from the planes last known location to reach the strait a busy shipping lane the plane would have had to cross over the country presumably within the range of radar an earlier statement said the western coast of malaysia was now the focus but the airline subsequently said that phrase was an oversight it did not elaborate civil aviation chief azharuddin abdul rahman said the search remained on both sides of the country\n",
      "paul weeks was on the missing flight as he made his way to new job before leaving he had taken lots of photos of his family his wife has said she said he left her his wedding ring and watch in case something happened she has said she cant give up hope i would love him to walk through that door\n",
      "(20000, 3)\n",
      "(2000, 3)\n",
      "(2000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_df['id'].iloc[1])\n",
    "print(train_df['article'].iloc[1])\n",
    "print(train_df['summary'].iloc[1])\n",
    "print(train_df.shape)\n",
    "print(val_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2918e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sample(n=20000, random_state=42)\n",
    "test_df = test_df.sample(n=2000, random_state=42)\n",
    "val_df = val_df.sample(n=2000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb85438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, articles, summaries, tokenizer, max_length=512):\n",
    "        self.articles = articles\n",
    "        self.summaries = summaries\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.articles)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        article = str(self.articles[idx])\n",
    "        summary = str(self.summaries[idx])\n",
    "        \n",
    "        article_encoding = self.tokenizer(\n",
    "            article,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        summary_encoding = self.tokenizer(\n",
    "            summary,\n",
    "            max_length=128,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'article_input_ids': article_encoding['input_ids'].flatten(),\n",
    "            'article_attention_mask': article_encoding['attention_mask'].flatten(),\n",
    "            'summary_input_ids': summary_encoding['input_ids'].flatten(),\n",
    "            'summary_attention_mask': summary_encoding['attention_mask'].flatten()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ad2b61",
   "metadata": {},
   "source": [
    "### **BART BASE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3c7d7a",
   "metadata": {},
   "source": [
    "**DATA LOADER CREATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eba19e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "\n",
    "train_dataset = NewsDataset(\n",
    "    train_df['article'].values,\n",
    "    train_df['summary'].values,\n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "val_dataset = NewsDataset(\n",
    "    val_df['article'].values,\n",
    "    val_df['summary'].values,\n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "test_dataset = NewsDataset(\n",
    "    test_df['article'].values,\n",
    "    test_df['summary'].values,\n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b579a8d",
   "metadata": {},
   "source": [
    "**MODEL AND TRAINING DEFINITION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83602ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummarizationModel(nn.Module):\n",
    "    \"\"\"BART-based summarization model.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name='facebook/bart-base'):\n",
    "        super(SummarizationModel, self).__init__()\n",
    "        self.bart = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.bart(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        return outputs\n",
    "\n",
    "def calculate_rouge_scores(predictions, references, rouge_scorer):\n",
    "    \"\"\"Calculate ROUGE scores.\"\"\"\n",
    "    rouge1_scores = []\n",
    "    rouge2_scores = []\n",
    "    rougeL_scores = []\n",
    "    \n",
    "    for pred, ref in zip(predictions, references):\n",
    "        scores = rouge_scorer.score(ref, pred)\n",
    "        rouge1_scores.append(scores['rouge1'].fmeasure)\n",
    "        rouge2_scores.append(scores['rouge2'].fmeasure)\n",
    "        rougeL_scores.append(scores['rougeL'].fmeasure)\n",
    "    \n",
    "    return {\n",
    "        'rouge1': np.mean(rouge1_scores),\n",
    "        'rouge2': np.mean(rouge2_scores),\n",
    "        'rougeL': np.mean(rougeL_scores)\n",
    "    }\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, scheduler, device):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        # Move batch to device\n",
    "        input_ids = batch['article_input_ids'].to(device)\n",
    "        attention_mask = batch['article_attention_mask'].to(device)\n",
    "        labels = batch['summary_input_ids'].to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate_model(model, dataloader, tokenizer, device, rouge_scorer_obj):\n",
    "    \"\"\"Evaluate the model.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    references = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['article_input_ids'].to(device)\n",
    "            attention_mask = batch['article_attention_mask'].to(device)\n",
    "            labels = batch['summary_input_ids'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            total_loss += outputs.loss.item()\n",
    "            \n",
    "            # Generate summaries\n",
    "            generated_ids = model.bart.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_length=150,\n",
    "                num_beams=4,\n",
    "                early_stopping=True\n",
    "            )\n",
    "            \n",
    "            # Decode predictions and references\n",
    "            for i in range(len(generated_ids)):\n",
    "                pred = tokenizer.decode(generated_ids[i], skip_special_tokens=True)\n",
    "                ref = tokenizer.decode(labels[i], skip_special_tokens=True)\n",
    "                \n",
    "                predictions.append(pred)\n",
    "                references.append(ref)\n",
    "    \n",
    "    # Calculate ROUGE scores\n",
    "    rouge_scores = calculate_rouge_scores(predictions, references, rouge_scorer_obj)\n",
    "    \n",
    "    return total_loss / len(dataloader), rouge_scores\n",
    "\n",
    "def train_model(model, train_dataloader, val_dataloader, tokenizer, device, num_epochs=3, learning_rate=5e-5):\n",
    "    \"\"\"Train the model.\"\"\"\n",
    "    # Initialize ROUGE scorer\n",
    "    rouge_scorer_obj = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    \n",
    "    # Setup optimizer and scheduler\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    total_steps = len(train_dataloader) * num_epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # Training loop\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    rouge_scores_history = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "        \n",
    "        # Train\n",
    "        train_loss = train_epoch(model, train_dataloader, optimizer, scheduler, device)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Evaluate\n",
    "        val_loss, rouge_scores = evaluate_model(model, val_dataloader, tokenizer, device, rouge_scorer_obj)\n",
    "        val_losses.append(val_loss)\n",
    "        rouge_scores_history.append(rouge_scores)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}\")\n",
    "        print(f\"ROUGE-1: {rouge_scores['rouge1']:.4f}\")\n",
    "        print(f\"ROUGE-2: {rouge_scores['rouge2']:.4f}\")\n",
    "        print(f\"ROUGE-L: {rouge_scores['rougeL']:.4f}\")\n",
    "    \n",
    "    return train_losses, val_losses, rouge_scores_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3058f9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(train_losses, val_losses, rouge_scores_history):\n",
    "    \"\"\"Plot training history.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Loss plots\n",
    "    axes[0, 0].plot(train_losses, label='Train Loss')\n",
    "    axes[0, 0].plot(val_losses, label='Validation Loss')\n",
    "    axes[0, 0].set_title('Training and Validation Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # ROUGE scores\n",
    "    rouge1_scores = [scores['rouge1'] for scores in rouge_scores_history]\n",
    "    rouge2_scores = [scores['rouge2'] for scores in rouge_scores_history]\n",
    "    rougeL_scores = [scores['rougeL'] for scores in rouge_scores_history]\n",
    "    \n",
    "    axes[0, 1].plot(rouge1_scores, label='ROUGE-1', marker='o')\n",
    "    axes[0, 1].plot(rouge2_scores, label='ROUGE-2', marker='s')\n",
    "    axes[0, 1].plot(rougeL_scores, label='ROUGE-L', marker='^')\n",
    "    axes[0, 1].set_title('ROUGE Scores')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('ROUGE Score')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # Final ROUGE scores bar plot\n",
    "    final_scores = rouge_scores_history[-1]\n",
    "    rouge_types = list(final_scores.keys())\n",
    "    scores = list(final_scores.values())\n",
    "    \n",
    "    axes[1, 0].bar(rouge_types, scores, color=['blue', 'green', 'red'])\n",
    "    axes[1, 0].set_title('Final ROUGE Scores')\n",
    "    axes[1, 0].set_ylabel('Score')\n",
    "    axes[1, 0].grid(True, axis='y')\n",
    "    \n",
    "    # Learning curve\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    axes[1, 1].plot(epochs, train_losses, 'b-', label='Training Loss')\n",
    "    axes[1, 1].plot(epochs, val_losses, 'r-', label='Validation Loss')\n",
    "    axes[1, 1].set_title('Learning Curve')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Loss')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def generate_summary(model, tokenizer, article, device, max_length=150):\n",
    "    \"\"\"Generate summary for a single article.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize article\n",
    "    inputs = tokenizer(\n",
    "        article,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=512,\n",
    "        return_tensors='pt'\n",
    "    ).to(device)\n",
    "    \n",
    "    # Generate summary\n",
    "    with torch.no_grad():\n",
    "        summary_ids = model.bart.generate(\n",
    "            input_ids=inputs['input_ids'],\n",
    "            attention_mask=inputs['attention_mask'],\n",
    "            max_length=max_length,\n",
    "            num_beams=4,\n",
    "            early_stopping=True\n",
    "        )\n",
    "    \n",
    "    # Decode summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da555321",
   "metadata": {},
   "source": [
    "**Model definition and training process**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcd9b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SummarizationModel('facebook/bart-base')\n",
    "\n",
    "print(\"Starting training process:\")\n",
    "train_losses, val_losses, rouge_scores_history = train_model(\n",
    "    model, train_loader, val_loader, tokenizer, device, num_epochs=3, learning_rate=5e-5\n",
    "    )\n",
    "\n",
    "print(\"\\nSaving the model...\")\n",
    "model_save_path = 'best_bart_summarization_model.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'tokenizer': tokenizer,\n",
    "    'training_history': {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'rouge_scores': rouge_scores_history\n",
    "    }\n",
    "}, model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1eb041",
   "metadata": {},
   "source": [
    "**Training data visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a196bf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPlotting training history...\")\n",
    "plot_training_history(train_losses, val_losses, rouge_scores_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cac736d",
   "metadata": {},
   "source": [
    "**Test evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290bffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPerforming final evaluation on test data\")\n",
    "rouge_scorer_obj = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "test_loss, test_rouge_scores = evaluate_model(model, test_loader, tokenizer, device, rouge_scorer_obj)\n",
    "\n",
    "print(\"\\nFinal Test Results:\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(\"\\nROUGE Scores:\")\n",
    "for metric, score in test_rouge_scores.items():\n",
    "    print(f\"{metric}: {score:.6f}\")\n",
    "\n",
    "test_results = {\n",
    "    'test_loss': test_loss,\n",
    "    'rouge_scores': test_rouge_scores\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44a7609",
   "metadata": {},
   "source": [
    "**Summarization example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2b89ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSummarization Examples:\")\n",
    "\n",
    "test_articles = test_df['article'].values\n",
    "test_summaries = test_df['summary'].values\n",
    "sample_indices = [0, 1, 2]\n",
    "\n",
    "for i in sample_indices:\n",
    "    article = test_articles[i]\n",
    "    actual_summary = test_summaries[i]\n",
    "    generated_summary = generate_summary(model, tokenizer, article, device)\n",
    "    \n",
    "    print(f\"\\n=== Example {i+1} ===\")\n",
    "    print(f\"\\nOriginal Article (first 200 chars):\\n{article[:200]}...\")\n",
    "    print(f\"\\nActual Summary:\\n{actual_summary}\")\n",
    "    print(f\"\\nGenerated Summary:\\n{generated_summary}\")\n",
    "    \n",
    "    # Calculate ROUGE scores\n",
    "    rouge_scorer_obj = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = rouge_scorer_obj.score(actual_summary, generated_summary)\n",
    "    \n",
    "    print(\"\\nROUGE Scores:\")\n",
    "    print(f\"ROUGE-1: {scores['rouge1'].fmeasure:.4f}\")\n",
    "    print(f\"ROUGE-2: {scores['rouge2'].fmeasure:.4f}\")\n",
    "    print(f\"ROUGE-L: {scores['rougeL'].fmeasure:.4f}\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e38f999",
   "metadata": {},
   "source": [
    "### **BART LARGE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34278c5d",
   "metadata": {},
   "source": [
    "**Data loader and model creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf69958",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_large = BartTokenizer.from_pretrained('facebook/bart-large')\n",
    "model_large = SummarizationModel('facebook/bart-large')\n",
    "model_large = model_large.to(device)\n",
    "\n",
    "train_dataset_large = NewsDataset(\n",
    "    train_df['article'].values,\n",
    "    train_df['summary'].values,\n",
    "    tokenizer_large\n",
    ")\n",
    "\n",
    "val_dataset_large = NewsDataset(\n",
    "    val_df['article'].values,\n",
    "    val_df['summary'].values,\n",
    "    tokenizer_large\n",
    ")\n",
    "\n",
    "test_dataset_large = NewsDataset(\n",
    "    test_df['article'].values,\n",
    "    test_df['summary'].values,\n",
    "    tokenizer_large\n",
    ")\n",
    "\n",
    "train_loader_large = DataLoader(train_dataset_large, batch_size=8, shuffle=True)\n",
    "val_loader_large = DataLoader(val_dataset_large, batch_size=8, shuffle=False)\n",
    "test_loader_large = DataLoader(test_dataset_large, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9d7d39",
   "metadata": {},
   "source": [
    "**Model training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc04f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nStarting BART-large training process:\")\n",
    "train_losses_large, val_losses_large, rouge_scores_history_large = train_model(\n",
    "    model_large, \n",
    "    train_loader_large, \n",
    "    val_loader_large, \n",
    "    tokenizer_large, \n",
    "    device, \n",
    "    num_epochs=3, \n",
    "    learning_rate=2e-5 \n",
    ")\n",
    "\n",
    "print(\"\\nSaving the BART-large model...\")\n",
    "model_save_path_large = 'best_bart_large_summarization_model.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': model_large.state_dict(),\n",
    "    'tokenizer': tokenizer_large,\n",
    "    'training_history': {\n",
    "        'train_losses': train_losses_large,\n",
    "        'val_losses': val_losses_large,\n",
    "        'rouge_scores': rouge_scores_history_large\n",
    "    }\n",
    "}, model_save_path_large)\n",
    "print(f\"Model saved to {model_save_path_large}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c28e71c",
   "metadata": {},
   "source": [
    "**Training data visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b83501",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPlotting BART-large training history...\")\n",
    "plot_training_history(train_losses_large, val_losses_large, rouge_scores_history_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b02019",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPerforming final evaluation on test data with BART-large\")\n",
    "rouge_scorer_obj = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "test_loss_large, test_rouge_scores_large = evaluate_model(\n",
    "    model_large, \n",
    "    test_loader_large, \n",
    "    tokenizer_large, \n",
    "    device, \n",
    "    rouge_scorer_obj\n",
    ")\n",
    "\n",
    "print(\"\\nFinal Test Results (BART-large):\")\n",
    "print(f\"Test Loss: {test_loss_large:.4f}\")\n",
    "print(\"\\nROUGE Scores:\")\n",
    "for metric, score in test_rouge_scores_large.items():\n",
    "    print(f\"{metric}: {score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a3612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nBART-large Summarization Examples:\")\n",
    "sample_indices = [0, 1, 2]\n",
    "\n",
    "for i in sample_indices:\n",
    "    article = test_articles[i]\n",
    "    actual_summary = test_summaries[i]\n",
    "    generated_summary = generate_summary(model_large, tokenizer_large, article, device)\n",
    "    \n",
    "    print(f\"\\n=== Example {i+1} ===\")\n",
    "    print(f\"\\nOriginal Article (first 200 chars):\\n{article[:200]}...\")\n",
    "    print(f\"\\nActual Summary:\\n{actual_summary}\")\n",
    "    print(f\"\\nGenerated Summary (BART-large):\\n{generated_summary}\")\n",
    "    \n",
    "    # Calculate ROUGE scores\n",
    "    scores = rouge_scorer_obj.score(actual_summary, generated_summary)\n",
    "    \n",
    "    print(\"\\nROUGE Scores:\")\n",
    "    print(f\"ROUGE-1: {scores['rouge1'].fmeasure:.4f}\")\n",
    "    print(f\"ROUGE-2: {scores['rouge2'].fmeasure:.4f}\")\n",
    "    print(f\"ROUGE-L: {scores['rougeL'].fmeasure:.4f}\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a42b7cc",
   "metadata": {},
   "source": [
    "**BASE vs LARGE model result comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03b5d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nModel Comparison - Test Results:\")\n",
    "print(\"\\nBART-base vs BART-large\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Test Loss - Base: {test_loss:.4f} | Large: {test_loss_large:.4f}\")\n",
    "for metric in test_rouge_scores:\n",
    "    print(f\"{metric} - Base: {test_rouge_scores[metric]:.4f} | Large: {test_rouge_scores_large[metric]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
