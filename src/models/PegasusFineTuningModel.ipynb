{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aac813a",
   "metadata": {},
   "source": [
    "### DEEP LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2eec05",
   "metadata": {},
   "source": [
    "# **TEXT SUMMARIZATION MODEL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccd032a",
   "metadata": {},
   "source": [
    "**IMPORTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69f93717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import ast\n",
    "import re\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from rouge_score import rouge_scorer\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from evaluate import load  # Changed from datasets import load_metric\n",
    "from torch.optim import AdamW\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a50cf12",
   "metadata": {},
   "source": [
    "**DATA LOADING AND PREPROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed5068e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataframe shape: (287114, 3)\n",
      "Test dataframe shape: (11491, 3)\n",
      "Validation dataframe shape: (13369, 3)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/train.csv', header=None)\n",
    "test_df = pd.read_csv('../data/test.csv', header=None)\n",
    "val_df = pd.read_csv('../data/validation.csv', header=None)\n",
    "\n",
    "columns = ['id', 'article', 'summary']\n",
    "train_df.columns = columns\n",
    "test_df.columns = columns\n",
    "val_df.columns = columns\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "def clean_article_heading(article):\n",
    "    pattern = r'By\\s*\\.\\s*.*?\\s*\\.\\s*PUBLISHED:\\s*\\.\\s*\\d+:\\d+\\s*EST,\\s*\\d+\\s*[A-Za-z]+\\s*\\d+\\s*\\.\\s*\\|\\s*\\.\\s*UPDATED:\\s*\\.\\s*\\d+:\\d+\\s*EST,\\s*\\d+\\s*[A-Za-z]+\\s*\\d+\\s*\\.'\n",
    "    cleaned_text = re.sub(pattern, '', article)\n",
    "    return cleaned_text.strip()\n",
    "\n",
    "train_df['article'] = train_df['article'].apply(preprocess_text)\n",
    "train_df['article'] = train_df['article'].apply(clean_article_heading)\n",
    "train_df['summary'] = train_df['summary'].apply(preprocess_text)\n",
    "test_df['article'] = test_df['article'].apply(preprocess_text)\n",
    "test_df['article'] = test_df['article'].apply(clean_article_heading)\n",
    "test_df['summary'] = test_df['summary'].apply(preprocess_text)\n",
    "val_df['article'] = val_df['article'].apply(preprocess_text)\n",
    "val_df['article'] = val_df['article'].apply(clean_article_heading)\n",
    "val_df['summary'] = val_df['summary'].apply(preprocess_text)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Training dataframe shape: {train_df.shape}\")\n",
    "print(f\"Test dataframe shape: {test_df.shape}\")\n",
    "print(f\"Validation dataframe shape: {val_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b0a7fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94eee5dc5070400aa56c9c9cb9c2d665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/88.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b65e5a6411248b19d487eb3842036ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbbfd8cbc1de4f87854656060b3d6906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pegasusTokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-cnn_dailymail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5c5a24",
   "metadata": {},
   "source": [
    "**Amount reduction for training time optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfd28a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sample(n=20000, random_state=42)\n",
    "test_df = test_df.sample(n=2000, random_state=42)\n",
    "val_df = val_df.sample(n=2000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6767ea80",
   "metadata": {},
   "source": [
    "**CUSTOM DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6d3f8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 20000\n",
      "Validation samples: 2000\n",
      "Testing samples: 2000\n"
     ]
    }
   ],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, articles, summaries, tokenizer, max_length=512):\n",
    "        self.articles = articles\n",
    "        self.summaries = summaries\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.articles)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        article = str(self.articles[idx])\n",
    "        summary = str(self.summaries[idx])\n",
    "        \n",
    "        article_encoding = self.tokenizer(\n",
    "            article,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        summary_encoding = self.tokenizer(\n",
    "            summary,\n",
    "            max_length=128,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'article_input_ids': article_encoding['input_ids'].flatten(),\n",
    "            'article_attention_mask': article_encoding['attention_mask'].flatten(),\n",
    "            'summary_input_ids': summary_encoding['input_ids'].flatten(),\n",
    "            'summary_attention_mask': summary_encoding['attention_mask'].flatten()\n",
    "        }\n",
    "\n",
    "train_dataset = NewsDataset(\n",
    "    train_df['article'].values,\n",
    "    train_df['summary'].values,\n",
    "    pegasusTokenizer\n",
    ")\n",
    "\n",
    "val_dataset = NewsDataset(\n",
    "    val_df['article'].values,\n",
    "    val_df['summary'].values,\n",
    "    pegasusTokenizer\n",
    ")\n",
    "\n",
    "test_dataset = NewsDataset(\n",
    "    test_df['article'].values,\n",
    "    test_df['summary'].values,\n",
    "    pegasusTokenizer\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Testing samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a126769",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PegasusForSummarization:\n",
    "    def __init__(self, model_name=\"google/pegasus-cnn_dailymail\", device='cuda'):\n",
    "        self.tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "        self.model = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "        self.device = device\n",
    "        self.rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "        \n",
    "    def train(self, train_loader, val_loader, epochs=3, learning_rate=5e-5, warmup_steps=500, weight_decay=0.01):\n",
    "        # Set up optimizer\n",
    "        optimizer = AdamW(self.model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        \n",
    "        # Set up scheduler\n",
    "        total_steps = len(train_loader) * epochs\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer, \n",
    "            num_warmup_steps=warmup_steps, \n",
    "            num_training_steps=total_steps\n",
    "        )\n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        best_model = None\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Training\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            train_progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} [Training]')\n",
    "            \n",
    "            for batch in train_progress_bar:\n",
    "                # Move batch to device\n",
    "                input_ids = batch['article_input_ids'].to(self.device)\n",
    "                attention_mask = batch['article_attention_mask'].to(self.device)\n",
    "                labels = batch['summary_input_ids'].to(self.device)\n",
    "                decoder_attention_mask = batch['summary_attention_mask'].to(self.device)\n",
    "                \n",
    "                # Clear gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = self.model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels,\n",
    "                    decoder_attention_mask=decoder_attention_mask\n",
    "                )\n",
    "                \n",
    "                loss = outputs.loss\n",
    "                train_loss += loss.item()\n",
    "                \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                \n",
    "                # Clip gradients\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "                \n",
    "                # Update parameters\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                \n",
    "                # Update progress bar\n",
    "                train_progress_bar.set_postfix({'loss': loss.item()})\n",
    "            \n",
    "            avg_train_loss = train_loss / len(train_loader)\n",
    "            \n",
    "            # Validation\n",
    "            val_loss, rouge_scores = self.evaluate(val_loader)\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "            print(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
    "            print(f\"  Val Loss: {val_loss:.4f}\")\n",
    "            print(f\"  Rouge1: {rouge_scores['rouge1']:.4f}\")\n",
    "            print(f\"  Rouge2: {rouge_scores['rouge2']:.4f}\")\n",
    "            print(f\"  RougeL: {rouge_scores['rougeL']:.4f}\")\n",
    "            \n",
    "            # Save best model\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model = copy.deepcopy(self.model.state_dict())\n",
    "                print(f\"  New best model saved with validation loss: {val_loss:.4f}\")\n",
    "        \n",
    "        # Load best model\n",
    "        if best_model is not None:\n",
    "            self.model.load_state_dict(best_model)\n",
    "            print(f\"Loaded best model with validation loss: {best_val_loss:.4f}\")\n",
    "    \n",
    "    def evaluate(self, data_loader, max_length=128, num_beams=4):\n",
    "        self.model.eval()\n",
    "        val_loss = 0\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "                # Move batch to device\n",
    "                input_ids = batch['article_input_ids'].to(self.device)\n",
    "                attention_mask = batch['article_attention_mask'].to(self.device)\n",
    "                labels = batch['summary_input_ids'].to(self.device)\n",
    "                decoder_attention_mask = batch['summary_attention_mask'].to(self.device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = self.model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels,\n",
    "                    decoder_attention_mask=decoder_attention_mask\n",
    "                )\n",
    "                \n",
    "                val_loss += outputs.loss.item()\n",
    "                \n",
    "                # Generate summaries\n",
    "                generated_ids = self.model.generate(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    max_length=max_length,\n",
    "                    num_beams=num_beams,\n",
    "                    repetition_penalty=2.5,\n",
    "                    length_penalty=1.0,\n",
    "                    early_stopping=True\n",
    "                )\n",
    "                \n",
    "                # Decode generated summaries and reference summaries\n",
    "                preds = [self.tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "                targets = [self.tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True) for t in labels]\n",
    "                \n",
    "                all_preds.extend(preds)\n",
    "                all_targets.extend(targets)\n",
    "        \n",
    "        # Calculate average validation loss\n",
    "        avg_val_loss = val_loss / len(data_loader)\n",
    "        \n",
    "        # Calculate ROUGE scores\n",
    "        rouge_scores = {'rouge1': 0, 'rouge2': 0, 'rougeL': 0}\n",
    "        for pred, target in zip(all_preds, all_targets):\n",
    "            scores = self.rouge_scorer.score(target, pred)\n",
    "            rouge_scores['rouge1'] += scores['rouge1'].fmeasure\n",
    "            rouge_scores['rouge2'] += scores['rouge2'].fmeasure\n",
    "            rouge_scores['rougeL'] += scores['rougeL'].fmeasure\n",
    "        \n",
    "        # Calculate average ROUGE scores\n",
    "        for key in rouge_scores:\n",
    "            rouge_scores[key] /= len(all_preds)\n",
    "        \n",
    "        return avg_val_loss, rouge_scores\n",
    "    \n",
    "    def predict(self, article, max_length=128, num_beams=4):\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Preprocess article\n",
    "        article = preprocess_text(article)\n",
    "        article = clean_article_heading(article)\n",
    "        \n",
    "        # Tokenize article\n",
    "        inputs = self.tokenizer(\n",
    "            article,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Generate summary\n",
    "        with torch.no_grad():\n",
    "            generated_ids = self.model.generate(\n",
    "                input_ids=inputs['input_ids'],\n",
    "                attention_mask=inputs['attention_mask'],\n",
    "                max_length=max_length,\n",
    "                num_beams=num_beams,\n",
    "                repetition_penalty=2.5,\n",
    "                length_penalty=1.0,\n",
    "                early_stopping=True\n",
    "            )\n",
    "        \n",
    "        # Decode summary\n",
    "        summary = self.tokenizer.decode(generated_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "        }, path)\n",
    "        self.tokenizer.save_pretrained(path + \"_tokenizer\")\n",
    "        print(f\"Model saved to {path}\")\n",
    "    \n",
    "    def load_model(self, path):\n",
    "        checkpoint = torch.load(path)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.tokenizer = PegasusTokenizer.from_pretrained(path + \"_tokenizer\")\n",
    "        print(f\"Model loaded from {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c7a3711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Initialize the model\n",
    "pegasus_model = PegasusForSummarization(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11b3c9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pegasus_model(model, epochs=3, learning_rate=3e-5):\n",
    "    # Training parameters\n",
    "    WARMUP_STEPS = 500\n",
    "    WEIGHT_DECAY = 0.01\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    model.train(\n",
    "        train_loader=train_loader, \n",
    "        val_loader=val_loader, \n",
    "        epochs=epochs, \n",
    "        learning_rate=learning_rate,\n",
    "        warmup_steps=WARMUP_STEPS,\n",
    "        weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5249d483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Evaluation function\n",
    "def evaluate_pegasus_model(model):\n",
    "    # Evaluate on test set\n",
    "    print(\"\\nEvaluating on test set...\")\n",
    "    test_loss, test_rouge_scores = model.evaluate(test_loader)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Rouge1: {test_rouge_scores['rouge1']:.4f}\")\n",
    "    print(f\"Test Rouge2: {test_rouge_scores['rouge2']:.4f}\")\n",
    "    print(f\"Test RougeL: {test_rouge_scores['rougeL']:.4f}\")\n",
    "    \n",
    "    return test_loss, test_rouge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "811419ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sample_summaries(model, samples=5):\n",
    "    print(\"\\nGenerating sample summaries:\")\n",
    "    for i in range(samples):\n",
    "        idx = np.random.randint(0, len(test_df))\n",
    "        article = test_df.iloc[idx]['article']\n",
    "        original_summary = test_df.iloc[idx]['summary']\n",
    "        \n",
    "        # Generate summary\n",
    "        generated_summary = model.predict(article)\n",
    "        \n",
    "        print(f\"\\nSample {i+1}:\")\n",
    "        print(f\"Original Summary: {original_summary}\")\n",
    "        print(f\"Generated Summary: {generated_summary}\")\n",
    "        \n",
    "        # Calculate ROUGE scores\n",
    "        scores = model.rouge_scorer.score(original_summary, generated_summary)\n",
    "        print(f\"Rouge1: {scores['rouge1'].fmeasure:.4f}\")\n",
    "        print(f\"Rouge2: {scores['rouge2'].fmeasure:.4f}\")\n",
    "        print(f\"RougeL: {scores['rougeL'].fmeasure:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01cecb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9edeadddd3fd4fca98b51e8ce5ab62d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 [Training]:   0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Cell 10: Example of how to run the training and evaluation\n",
    "# Uncomment and run the following lines when ready to train\n",
    "trained_model = train_pegasus_model(pegasus_model, epochs=3, learning_rate=3e-5)\n",
    "test_loss, test_rouge_scores = evaluate_pegasus_model(trained_model)\n",
    "trained_model.save_model(\"pegasus_summarization_model\")\n",
    "\n",
    "# Cell 11: Example of making predictions with the trained model\n",
    "# Uncomment and run the following line when ready to make predictions\n",
    "# predict_sample_summaries(trained_model, samples=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
